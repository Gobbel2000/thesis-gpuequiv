\section{Parallelizing the Algorithm}

At the center of this contribution is a parallel GPU-implementation%
\footnote{The code can be found at \url{https://github.com/Gobbel2000/gpuequiv}}
of the energy game introduced in Section~\ref{sec:energy_games}.
Given a game graph as input, it calcu\-lates for each position the energy budgets
required for the attacker, starting at the current position, to win the game.
This algorithm was described in~\cite{bisping2023process} as part of the
spectroscopy algorithm, as well as in~\cite{brihaye2023multi} by T. Brihaye and
A. Goeminne, which more generally covers
\enquote{Multi-Weighted Reachability Games},
but presents essentially the same algorithm structure.

% First, definitions that are also used outside the algorithm
\SetKwData{Updated}{updated}
\SetKwData{Energies}{energies}
\begin{algorithm}[ht]\label{alg:energy_game}
    \DontPrintSemicolon
    \SetKwData{Start}{start}
    \SetKwData{Visit}{visit}
    \SetKwData{New}{new\_energies}
    \SetKwFor{pFor}{for parallel}{do}{end}

    $\Start = \{g \in G_d \mid \mathrm{Succ}(g) = \emptyset\}$\;
    \lFor{$g \in \Start$}{$\Energies[g] = \{\mathbf{0}\}$}
    \lFor{$g \in G \setminus \Start$}{$\Energies[g] = \emptyset$}
    $\Visit = \{\mathrm{Pred}(g) \mid g \in \Start\}$\;

    \BlankLine
    \While{$\Visit \neq \emptyset$}{
        \pFor{$g \in \Visit$}{
            $\Visit = \Visit \setminus \{g\}$\;
            \For{$g' \in \mathrm{Succ}(g)$} {
                $\Updated[g'] = \{ \mathsf{upd}^{-1}(e, w(g, g')) \mid e \in \Energies[g'] \}$
            }

            \BlankLine
            \eIf(\tcp*[h]{attack positions}){$g \in G_a$}{
                $\New = \mathrm{Min} \left(
                    \bigcup_{g' \in \mathrm{Succ}(g)} \uparrow \Updated[g']
                \right)$
            } (\tcp*[h]{defend positions}) {
                $\New = \mathrm{Min} \left(
                    \bigcap_{g' \in \mathrm{Succ}(g)} \uparrow \Updated[g']
                \right)$
            }

            \BlankLine
            \If{$\New \neq \Energies[g]$}{
                $\Energies[g] = \New$\;
                $\Visit = \Visit \cup \mathrm{Pred}(g)$\;
            }
        }
    }
    \Return{\Energies}

    \caption{Parallel Energy Game}
\end{algorithm}

The basic structure is as shown in Algorithm~\ref{alg:energy_game}.
In order to calculate all the winning budgets,
we start at the end of the game graph and work our way backwards.
At all defend positions with no successors the attacker immediately wins,
so we can set the energies required for the attacker to win there to the
0-valued energy tuple (lines 1--3).
In every iteration a set of positions is visited which updates its associated
energies.
The next iteration visits the predecessors of all positions, whose energies
have changed in the previous iteration, thus walking backwards in the game
graph in a breadth-first manner. Once an iteration caused no changes to the
energies, the algorithm terminates.

We achieve parallelization by visiting all positions in the visit list in
parallel, but to fully take advantage of the massively multithreaded
GPU-architecture, each position is further processed by multiple threads.

The core of the algorithm lies in lines 11--15, where the upwards-closed sets of
energies are either unioned or intersected.
Since both operations demand very different approaches,
handling them in a single shader would inevitably incur high branch-divergence.
Therefore both cases are handled by separate, more regular shaders:
one for processing attack positions, another for defend positions.
This technique is known as \enquote{Kernel fission}
and improves resource utilization by allowing threads in a work group to follow
similar instruction paths~\cite{Hijma2023}.
The following two sections detail how these operations have been implemented to
efficiently run on a GPU\@.


\subsection{Attack shader: Union}

In order to calculate the union of the upwards-closed sets,
we can simply unionize the minimal elements that the sets are represented by:

\[\mathrm{Min} \left( \bigcup_{g' \in \mathrm{Succ}(g)} \uparrow \Updated[g'] \right) =
  \mathrm{Min} \left( \bigcup_{g' \in \mathrm{Succ}(g)}          \Updated[g'] \right)\]

The task thus becomes to simply
collect all energies of the current position's successors,
update them accordingly
and then filter out non-minimal energies.
This workflow is sketched out in Figure~\ref{fig:attack}.

\begin{figure}[ht]
\begin{center}
\begin{tikzpicture}
    \node[rectangle,draw] (start_node) {\large{$g$}};
    \node (successor1) [right=of start_node,label=above:successors] {$g_1'$};

    % Energies of successors
    \node (energy1_1) [right=of successor1] {$e_{g_1',1}$};
    \node (energy1_2) [below] at (energy1_1.south) {$e_{g_1',2}$};
    \node (dots1) [below] at (energy1_2.south) {\rvdots};
    \node (energy2_1) [below] at (dots1.south) {$e_{g_2',1}$};
    \node (energy2_2) [below] at (energy2_1.south) {$e_{g_2',2}$};
    \node (dots2) [below] at (energy2_2.south) {\rvdots};

    \node (successor2) [left=of energy2_1] {$g_2'$};
    \node (dots_successors) at (successor2 |- dots2) {\rvdots};

    % Updated energies
    \node (updated1_1) [right=of energy1_1] {$e_{g_1',1}'$};
    \node (updated1_2) [right=of energy1_2] {$e_{g_1',2}'$};
    \node (udots1) at (updated1_2 |- dots1) {\rvdots};
    \node (updated2_1) [right=of energy2_1] {$e_{g_2',1}'$};
    \node (updated2_2) [right=of energy2_2] {$e_{g_2',2}'$};
    \node (udots2) at (updated2_2 |- dots2) {\rvdots};
    % Include energies of g itself
    %\node (energyg_1) [below] at (udots2.south) {$e_{g,1}$};
    %\node (energyg_2) [below] at (energyg_1.south) {$e_{g,2}$};
    %\node (udots3) [below] at (energyg_2.south) {\rvdots};

    % Minimized energies
    \node (minimal1) [right=14mm of udots1.north] {$e_1^*$};
    \node (minimal2) [below] at (minimal1.south) {$e_2^*$};
    \node (mdots) [below] at (minimal2.south) {\rvdots};

    \draw[->] (start_node.east) -- (successor1.west);
    \draw[->] (start_node.east) -- (successor2.west);
    \draw[->] (successor1) -- (energy1_1.west);
    \draw[->] (successor1) -- (energy1_2.west);
    \draw[->] (successor1) -- (energy1_2.west |- dots1);
    \draw[->] (successor2) -- (energy2_1.west);
    \draw[->] (successor2) -- (energy2_2.west);
    \draw[->] (successor2) -- (energy2_2.west |- dots2);

    \draw[->] (energy1_1) -- node (l_update) [above=2mm] {update} (updated1_1);
    \draw[->] (energy1_2) -- (updated1_2);
    \draw[->] (energy1_2.east |- dots1) -- (updated1_2.west |- udots1);
    \draw[->] (energy2_1) -- (updated2_1);
    \draw[->] (energy2_2) -- (updated2_2);
    \draw[->] (energy2_2.east |- dots2) -- (updated2_2.west |- udots2);
    % Energies from g
    %\draw[->,shorten >= 4mm] (start_node.south) |-
    %    node [near end,below] {energies of $g$}
    %    (energyg_2.west);

    % Diagonal lines suggesting the reduction to minimal energies
    \draw[thick] (updated1_1.east |- udots2.south) -- (minimal1.west |- mdots.south);
    \draw[thick] (updated1_1.north east) -- (minimal1.north west);
    \node (l_minimize) [right=7mm of l_update] {minimize};
\end{tikzpicture}
\end{center}
\caption{Data flow for processing Attack positions}%
\label{fig:attack}
\end{figure}

The layout of this figure suggests a very natural way to further parallelize
the processing of attack nodes:
we spawn one thread for each energy tuple.
The shader then has two tasks:
\begin{enumerate}
    \item Update its energy using the correct edge weight,
    \item Figure out if it should be kept as a minimal energy or discarded.
\end{enumerate}

The update step basically follows the definition of $\mathsf{upd}^{-1}$.
Minimizing the energies is done by comparing all energy tuples with each other.
Let $n = \sum_{g' \in \mathrm{Succ}(g)} | \Energies[g'] |$ be the total number
of energies considered for a starting node $g$.
We do $n^2$ comparisons in total, where each thread checks all $n$
energies to find out if this thread's energy is part of the minimal set.
If the thread for energy $e$ encounters an energy $e'$ with $e' \leq e$,
energy $e$ is not minimal and will be filtered out. If $e = e'$, the thread
index is used as a tie breaker to avoid any duplicates.

Theoretically only half of the comparisons could be performed by pruning symmetric
pairs (i.e.\ compare only $e_1$ with $e_2$, not also $e_2$ with $e_1$),
but this would make the comparison itself more expensive by not only requiring
the componentwise comparison of $e_1 \leq e_2$, but also $e_1 \geq e_2$.
Even bigger problems arise when trying to map this approach to the GPU
execution model:
A thread would possibly have to write flags for which energies to keep not only
for its \enquote{own} energy,
but for any energy it's comparing it with.
Such cross-thread memory writes make synchronization more difficult.
Distributing symmetry-reduced comparisons to multiple threads is also
more complex than each thread just comparing its energy with all others.

\subsection{Defend shader: Intersection}

\section{Data Layout}

\section{Limitations}
