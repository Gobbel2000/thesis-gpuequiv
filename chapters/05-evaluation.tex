This chapter will investigate the extent at which GPU-acceleration was able to
speed up execution of the spectroscopy algorithm.
Benchmarks were conducted to compare the performance of the new,
parallelized program \texttt{gpuequiv}
with the original implementation of the same algorithm by Bisping,
created alongside~\cite{bisping2023process}.
We will further look into what was done to verify the correctness of the GPU
implementation.

\section{Benchmarks}

The performance of the implementation was assessed by running it on files from
the \enquote{Very Large Transition System Benchmark Suite} (VLTS)~\cite{vlts},
which, as the name suggests,
includes transition systems with large numbers of states.
For the benchmark, the task is to find the equivalences between \emph{all}
process pairs within a transition system.
The energy game is constructed to include all process pairs that we want to
compare,
but there are some very impactful reductions we can apply to end up with
significantly less than $|\mathsf{Proc}|^2$ starting positions.

Firstly, we can minimize the LTS by consolidating bisimilar processes.
The bisimulation of an LTS can be computed quite efficiently---certainly much
faster than the full spectroscopy algorithm---with the help of a procedure
based around partition refinement~\cite{Blom2002}.
That way we end up with a smaller transition system with just one process for
each bisimulation class of the original system.
Because bisimilarity is already the strongest notion of equivalence,
all processes within a bisimulation class must behave the same for any
equivalence comparison,
so there is no information lost by performing this reduction step.

Secondly,
we can reduce the search space by inspecting the other end of the spectrum.
If two process are already not enabledness-equivalent,
then none of the other equivalences can hold either,
making any further spectroscopy redundant.
Comparing the enabled actions of two processes is trivially easy,
so any starting positions comparing processes with distinct action sets
can simply be discarded.

The benchmark results are listed in Table~\ref{tab:benchmarks}.
The first column lists the name of the transition system.
Except for \texttt{peterson}, all systems originate from the VLTS Benchmark
Suite.
Next, the number of processes and bisimulation classes ($\sim_B$) is listed,
where $\sim_B$ represents the number of processes left after minimization.
A better metric of the input size for estimating the runtime of the algorithm
is the size of the game graph.
The number of positions and moves is listed.
Finally, the last three columns contain the runtimes of both implementations in
seconds.
The original CPU-based implementation written in the Scala programming
language as part of~\cite{bisping2023process} is listed first,
next to it the runtimes of the GPU-accelerated version \texttt{gpuequiv}.
Both measurements include everything from generating the energy game until
all winning energies are computed, but not the initial minimization step.
The last column lists just the time spent by \texttt{gpuequiv} solving the
energy game, which is where all GPU-computations are situated at.

All benchmarks were run on the same machine with an AMD 5800X processor,
32GB of RAM and an AMD RX 6700XT graphics card with 12GB of VRAM\@.

\begin{table}[htpb]
    \centering
    \caption{Benchmarks for finding all equivalences in an LTS\@.
        The last column shows just the time that \texttt{gpuequiv} spent
        processing the created energy game,
        excluding the time needed to generate the game.
    }%
    \label{tab:benchmarks}
    \small
    \begin{tabular}{@{}l
                    r@{\hskip 6pt}r
                    r@{\hskip 6pt}r
                    S[table-format=3.3]@{\hskip 6pt}
                    S[table-format=2.4]@{\hskip 6pt}
                    S[table-format=1.4]@{}}
        \toprule
        &\multicolumn{2}{c}{LTS size}
        &\multicolumn{2}{c}{Game Graph size}
        &\multicolumn{3}{c}{Runtime (s)} \\
        \cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(l){6-8}
        LTS~\cite{vlts}
        &$|\mathsf{Proc}|$ &$\sim_B$
        &$|G|$ &$|E|$
        &\cite{bisping2023process} &{gpuequiv} &{Game} \\
        \midrule

        \texttt{peterson}~\cite{bisping2023process}
                              &20     &19     &601        &1856        &0.137 &0.0058 &0.0054 \\
        \texttt{vasy\_0\_1}   &289    &9      &260        &749         &0.018 &0.0046 &0.0044 \\
        \texttt{vasy\_1\_4}   &1183   &28     &520        &1303        &0.019 &0.0052 &0.0050 \\
        \texttt{vasy\_5\_9}   &5486   &145    &1703       &3080        &0.039 &0.0054 &0.0049 \\
        \texttt{vasy\_8\_24}  &8879   &416    &59,531     &145,576     &1.35  &0.066  &0.0417 \\
        \texttt{vasy\_8\_38}  &8921   &219    &7304       &19,634      &0.131 &0.0093 &0.0067 \\
        \texttt{vasy\_10\_56} &10,849 &2112   &1,947,316  &6,044,124   &109.0 &5.46   &4.07   \\
        \texttt{vasy\_18\_73} &18,746 &4087   &75,808,284 &623,482,227 &{--}  &{--}   &{--}   \\
        \texttt{vasy\_25\_25} &25,217 &25,217 &0          &0           &0.217 &0.0078 &0.0021 \\
        \texttt{cwi\_1\_2}    &1952   &1132   &8,503,411  &22,683,038  &229.0 &17.7   &8.91   \\
        \texttt{cwi\_3\_14}   &3996   &62     &11,094     &24,045      &0.192 &0.0227 &0.0193 \\
        \bottomrule
    \end{tabular}
\end{table}

A few notable things can be gathered from the data in
Table~\ref{tab:benchmarks}.
Most importantly, the GPU-accelerated version could in fact achieve
a clear and significant reduction in runtime,
with 10--20x speedups on the larger inputs.
This can mostly be attributed to the high degree of parallelization provided by
the GPU,
but many other factors are also at play.
These benchmarks can not answer the question as to how far one could get with
a purely CPU-based optimized implementation.

Looking at the game graph sizes in relation to the corresponding LTS sizes
gives an impression as to how quickly the game graph can explode
and how its size presents the main challenge for any scalable implementation of
the spectroscopy algorithm.
The size of the game is not only dependent on the number of processes in the
input LTS,
but also on its structural properties,
such as how much non-determinism it exhibits
(a process is non-deterministic if it has multiple transitions with the same
action).
This explains why the game graph for \texttt{cwi\_1\_2} is much larger
than the game graph for \texttt{vasy\_10\_56},
even though the latter has almost twice as many states after minimization.
The LTS \texttt{vasy\_25\_25} is a curiosity
because it produces an empty game graph.
This is due to the fact that each processes in this system has a transition
with a unique action,
so there is not a single enabledness-equivalent process pair.
Therefore, there are no starting positions for the game graph and we already
know that no equivalence holds anywhere in the system.

The LTS \texttt{vasy\_18\_73} could not be computed by either implementation
because of memory constraints.
\texttt{gpuequiv} created the energy game in 112 seconds,
but the graph was slightly too large to fit into a GPU buffer:
as mentioned in Section~\ref{subsec:hw_limits},
the largest graph we can load has 536\,870\,911 edges.
Unfortunately, that means that,
when looking at this set of benchmarks,
we could not achieve higher scalability by processing larger transition systems
than before.

\section{Correctness}

The correctness of the implementation is verified with an automated test suite.
This includes high-level integration tests checking that the correct
equivalences are reported for an LTS,
as well as more granular unit tests that check individual types or just a
single shader invocation.
A few manually constructed energy games are also tested in addition to the ones
generated by the spectroscopy algorithm
to validate the usability of the library for energy games in general.

Along with the benchmarks, there are some output values included
in~\cite{bisping2023process}
that can be used to verify the results of running the algorithm on the VLTS
files.
This includes the sizes of the equivalence quotients with regards to
enabledness, trace-equivalence and simulation.
These values are reproduced by \texttt{gpuequiv}
and when ensuring that both implementations perform the same operations,
all numbers match up exactly.
This gives a high confidence for the correctness of \texttt{gpuequiv},
even for larger inputs.
